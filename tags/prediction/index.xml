<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Prediction | L. Collado-Torres</title>
    <link>https://lcolladotor.github.io/tags/prediction/</link>
      <atom:link href="https://lcolladotor.github.io/tags/prediction/index.xml" rel="self" type="application/rss+xml" />
    <description>Prediction</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2011-2020. All thoughts and opinions here are my own. The icon was designed by [Mauricio Guzmán](https://www.linkedin.com/in/mauricio-guzman-6529b551/) and is inspired by [Huichol culture](https://en.wikipedia.org/wiki/Huichol); it represents my community building interests</copyright><lastBuildDate>Mon, 17 Sep 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://lcolladotor.github.io/images/icon_hu2b32c4ab415f12f472f73c7b0301b0d1_19400_512x512_fill_lanczos_center_2.png</url>
      <title>Prediction</title>
      <link>https://lcolladotor.github.io/tags/prediction/</link>
    </image>
    
    <item>
      <title>What about a lawyer-like app as the minimum help for defendants in immigration cases?</title>
      <link>https://lcolladotor.github.io/2018/09/17/what-about-a-lawyer-like-app-as-the-mininum-help-for-defandants-in-immigration-cases/</link>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://lcolladotor.github.io/2018/09/17/what-about-a-lawyer-like-app-as-the-mininum-help-for-defandants-in-immigration-cases/</guid>
      <description>


&lt;p&gt;Today I attended the special panel discussion event at JHSPH called &lt;a href=&#34;http://hopkinshumanitarianhealth.org/news-events/events/separated-child-separation-at-the-border-a-health-and-human-rights-perspect&#34;&gt;“Separated: Children Separation at the Border A Health and Human Rights Perspective”&lt;/a&gt;. It got my mind racing and here’s an idea. It’s likely (definitely) incomplete, but maybe it’ll get others to think on related ideas.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://lcolladotor.github.io/post/2018-09-17-what-about-a-lawyer-like-app-as-the-mininum-help-for-defandants-in-immigration-cases_files/ChildSepBorder.jpg&#34; width=&#34;500&#34; /&gt;
&lt;a href=&#34;http://hopkinshumanitarianhealth.org/news-events/events/separated-child-separation-at-the-border-a-health-and-human-rights-perspect&#34;&gt;Image source&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;panel-summary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Panel summary&lt;/h3&gt;
&lt;p&gt;The panel was composed by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/ColleenKraft&#34;&gt;Colleen Kraft&lt;/a&gt;, President, American Academy of Pediatrics&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/EricSchwartzRI&#34;&gt;Eric Schwartz&lt;/a&gt;, President, Refugee International&lt;/li&gt;
&lt;li&gt;George Escobar, Chief of Program and Services, &lt;a href=&#34;https://wearecasa.org/who-we-are/&#34;&gt;CASA de Maryland&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/pbspiegel&#34;&gt;Paul Spiegel&lt;/a&gt;, Director, Center for Humanitarian Health&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I missed the first 30 minutes or so but I still got to listen to most of it. The panel members presented many facts and here are some that will be relevant to the idea I have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Child separation is just one of the consequences of the current’s administration immigration policies implemented and enforced by the Department of Justice (ultimately headed by Jeff Sessions, the US Attorney General).&lt;/li&gt;
&lt;li&gt;The US is the only country (to the panel’s members knowledge) with a child separation policy.&lt;/li&gt;
&lt;li&gt;Due to empathy many individuals across political lines reacted against child separation.&lt;/li&gt;
&lt;li&gt;The US immigration system won’t really change much even if Democrats get elected. Obama did deport over 2 million individuals, though he prioritized &lt;em&gt;criminals&lt;/em&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Arrested immigrants are not required by law to have representation (a lawyer) provided by the government&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Minors (say 3 year old children) with no lawyers are being highlighted in the media.&lt;/li&gt;
&lt;li&gt;Immigration cases where the defendants have lawyers drastically improve&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; the odds for the defendants.&lt;/li&gt;
&lt;li&gt;Immigration judges are human.&lt;/li&gt;
&lt;li&gt;Immigration judges typically used to (or maybe still do) try to give time for a minor to get a lawyer.&lt;/li&gt;
&lt;li&gt;Immigration judges are &lt;em&gt;alledgely&lt;/em&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; being pressured to meet quotas in the range of 700 to 1,000 cases by year under the current administration. Thus judges sometimes have to close cases in a couple of hours.&lt;/li&gt;
&lt;li&gt;Immigration judges now basically have 2 options for closing a case: order deportation or (I’m missing the correct term) &lt;em&gt;free&lt;/em&gt; the defendant.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the end the panel members highlighted that &lt;em&gt;we&lt;/em&gt; should take some type of action&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; but that we should consider the consequences of our suggested policy changes. They also mentioned that we should take advantage of this moment (child separation got everyone’s attention) to raise the profile of the other problems with the current immigration policies.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;my-way-of-taking-action-heres-an-idea&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;My way of taking action: here’s an idea&lt;/h3&gt;
&lt;p&gt;I’m by no means an immigration expert. My way of taking action is to share ideas, like &lt;a href=&#34;http://lcolladotor.github.io/2017/01/25/An-alternative-to-the-Mexico-US-wall-where-the-US-would-gain-millions-of-dollars/#.W6BV4v5Kg0o&#34;&gt;I’ve done in the past&lt;/a&gt;, that might be incomplete, unrealistic or even super flawed, but that hopefully motivate others.&lt;/p&gt;
&lt;p&gt;The bare bones version of my idea was: what if immigrants could have an &lt;em&gt;automatic&lt;/em&gt; (programmed) lawyer and translator during their hearings? This would not be a replacement for actually having lawyers (say those provided by local governments or NGOs as George Escobar mentioned) but would raise the minimum bar for those immigrants who currently have their cases processed with no lawyers at all.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-into-the-details&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Getting into the details&lt;/h3&gt;
&lt;p&gt;Imagine that we could get our hands on dozens/hundreds/thousands? of transcripts of immigration court hearings where we have the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;what the judge said&lt;/li&gt;
&lt;li&gt;what the government’s lawyer said&lt;/li&gt;
&lt;li&gt;what the defendant’s lawyer said (either to the judge or to the defendant)&lt;/li&gt;
&lt;li&gt;what the defendant said&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Just like a script for a play. We would additionally need a table with court hearing metadata such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Outcome: deportation, being &lt;em&gt;freed&lt;/em&gt; (term?).&lt;/li&gt;
&lt;li&gt;Date of the hearing.&lt;/li&gt;
&lt;li&gt;State where the hearing occurred.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then using machine learning (maybe with deep learning methods) process the text and try to determine potential suggestions an actual defendant’s lawyer would give to its defendant or respond to the judge/government’s lawyer. It might not always get things right, but I imagine that it would be better than the current state of affairs.&lt;/p&gt;
&lt;p&gt;The automatic lawyer would need then to work as say a phone app that listens to what others are saying in the room. Say have 3 icons with one per person present (judge, defendant, gov’s lawyer). Then the defendant presses each button when each person is talking. The app then shows some 1 to say 3 suggested responses (with translations)&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; and responds for the defendant in English once the defendant chooses an option (or goes with the top one).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;implementing-an-initial-version-of-the-app&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Implementing an initial version of the app&lt;/h3&gt;
&lt;p&gt;I think that large computing companies like Amazon, Microsoft and Google would be willing to provide some compute credits on their clouds for the initial version of the algorithm that is &lt;em&gt;listening&lt;/em&gt; to the court hearing and then provides suggestions. Think of this as the “suggested text” you get nowadays when typing emails on Gmail or text messages. Maybe these companies have programs where you can apply to have some of their engineers help you for a certain number of hours.&lt;/p&gt;
&lt;p&gt;I think that one big initial challenge would be to get that collection of transcripts from immigration court hearings where defendant lawyer(s) were present.&lt;/p&gt;
&lt;p&gt;I also imagine that automated lawyers are not allowed currently in courts. But compared to providing human lawyers in all immigration cases, this change might be more &lt;em&gt;realistic&lt;/em&gt; to pass as a law.&lt;/p&gt;
&lt;p&gt;I also imagine that some phone companies might be willing to provide some refurbished phones that only have this app installed and are kept safe in the immigration courts. And well, satisfy any security requirements the government has.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;improving-the-app&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Improving the app&lt;/h3&gt;
&lt;p&gt;Lets say that you get that alpha version of the app working. If we had volunteer lawyers annotate the transcripts with some information about the intent behind what each person said (it could start with just 3 options: negative, positive, neutral from the perspective of the defendant) that could maybe help the algorithm that processes the transcripts.&lt;/p&gt;
&lt;p&gt;If we also had more detailed court hearing metadata such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Location of the court (I imagine a that a few judges work in each court)&lt;/li&gt;
&lt;li&gt;Demographics of the defendants: like which country or even region of the country where they come from, whether the defendant has any family support, etc&lt;/li&gt;
&lt;li&gt;Category information for the court hearing (maybe cases can be grouped into a few categories)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;then I imagine that the app would be able to have more personalized experience, like re-adjust the suggestions based on which court you are located at and adapt the translations to the Spanish version the defendant is most familiar with (we say &lt;em&gt;buddy&lt;/em&gt; in so many different ways as shown below).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://lcolladotor.github.io/post/2018-09-17-what-about-a-lawyer-like-app-as-the-mininum-help-for-defandants-in-immigration-cases_files/bromap.png&#34; width=&#34;500&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.facebook.com/pictoline/photos/a.1611821172410355.1073741828.1598399590419180/1623937737865365/?type=1&amp;amp;fref=nf&#34;&gt;Image source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The app could also be connected to remote human immigration lawyers than can intervene remotely when the suggestions algorithm doensn’t know what to do. Maybe this could be part of some social service that immigration lawyers (regardless of their personal political preferences) could do as some elective during their formation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;doing-some-convincing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Doing some convincing&lt;/h3&gt;
&lt;p&gt;I think that you could try to get support for this automatic immigration lawyer by arguing that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It’s better than no lawyer.&lt;/li&gt;
&lt;li&gt;It’s cheaper than having lawyers for all cases.&lt;/li&gt;
&lt;li&gt;Improves processing times on average (ideally) such that immigration judges can fulfill their quotas (here I’m hoping that it reduces the rate at which cases are closed with deportation orders).&lt;/li&gt;
&lt;li&gt;Is more humane than having a minor with no help. Though I hope that immigration judges would still try to give time for children to secure a lawyer.&lt;/li&gt;
&lt;li&gt;Might be implemented earlier (years earlier?) than changes in immigration law requiring that all defendants have a human lawyer in immigration cases.&lt;/li&gt;
&lt;li&gt;If human lawyers can help through the app, then it also increases the number of jobs for immigration lawyers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This idea has potentially many flaws because like any system, people on both sides will try to game it. This is where having a large set of transcripts would be useful as well as continuous updates to the algorithm such that gaming the system actually becomes hard.&lt;/p&gt;
&lt;p&gt;As you can see, this is just an idea, or a collection of them around one theme. It would need serious work to implement.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;acknowledgments&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Acknowledgments&lt;/h3&gt;
&lt;p&gt;Do you want to listen to the whole panel discussion? From this tweet it looks like the recording will be available online:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Thank you &lt;a href=&#34;https://twitter.com/ColleenKraft?ref_src=twsrc%5Etfw&#34;&gt;@ColleenKraft&lt;/a&gt; (&lt;a href=&#34;https://twitter.com/AmerAcadPeds?ref_src=twsrc%5Etfw&#34;&gt;@AmerAcadPeds&lt;/a&gt;), &lt;a href=&#34;https://twitter.com/EricSchwartzRI?ref_src=twsrc%5Etfw&#34;&gt;@EricSchwartzRI&lt;/a&gt; (&lt;a href=&#34;https://twitter.com/RefugeesIntl?ref_src=twsrc%5Etfw&#34;&gt;@RefugeesIntl&lt;/a&gt;), George Escobar (CASA de Maryland) &amp;amp; &lt;a href=&#34;https://twitter.com/pbspiegel?ref_src=twsrc%5Etfw&#34;&gt;@pbspiegel&lt;/a&gt; (&lt;a href=&#34;https://twitter.com/Humanit_Health?ref_src=twsrc%5Etfw&#34;&gt;@Humanit_Health&lt;/a&gt;) for participating in today&amp;#39;s panel. A recorded version of the talk will be available on the &lt;a href=&#34;https://twitter.com/Humanit_Health?ref_src=twsrc%5Etfw&#34;&gt;@Humanit_Health&lt;/a&gt; website: &lt;a href=&#34;https://t.co/nXAvI5KJkm&#34;&gt;https://t.co/nXAvI5KJkm&lt;/a&gt;&lt;/p&gt;&amp;mdash; Johns Hopkins Bloomberg School of Public Health (@JohnsHopkinsSPH) &lt;a href=&#34;https://twitter.com/JohnsHopkinsSPH/status/1041732455865171972?ref_src=twsrc%5Etfw&#34;&gt;September 17, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;This blog post was made possible thanks to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://bioconductor.org/packages/3.10/BiocStyle&#34;&gt;BiocStyle&lt;/a&gt;&lt;/em&gt; &lt;a id=&#39;cite-Oles_2020&#39;&gt;&lt;/a&gt;(&lt;a href=&#39;https://github.com/Bioconductor/BiocStyle&#39;&gt;Oleś, Morgan, and Huber, 2020&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=blogdown&#34;&gt;blogdown&lt;/a&gt;&lt;/em&gt; &lt;a id=&#39;cite-Xie_2017&#39;&gt;&lt;/a&gt;(&lt;a href=&#39;https://github.com/rstudio/blogdown&#39;&gt;Xie, Hill, and Thomas, 2017&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=devtools&#34;&gt;devtools&lt;/a&gt;&lt;/em&gt; &lt;a id=&#39;cite-Wickham_2019&#39;&gt;&lt;/a&gt;(&lt;a href=&#39;https://CRAN.R-project.org/package=devtools&#39;&gt;Wickham, Hester, and Chang, 2019&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=knitcitations&#34;&gt;knitcitations&lt;/a&gt;&lt;/em&gt; &lt;a id=&#39;cite-Boettiger_2019&#39;&gt;&lt;/a&gt;(&lt;a href=&#39;https://CRAN.R-project.org/package=knitcitations&#39;&gt;Boettiger, 2019&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;
&lt;a id=&#39;bib-Boettiger_2019&#39;&gt;&lt;/a&gt;&lt;a href=&#34;#cite-Boettiger_2019&#34;&gt;[1]&lt;/a&gt;&lt;cite&gt;
C. Boettiger.
&lt;em&gt;knitcitations: Citations for ‘Knitr’ Markdown Files&lt;/em&gt;.
R package version 1.0.10.
2019.
URL: &lt;a href=&#34;https://CRAN.R-project.org/package=knitcitations&#34;&gt;https://CRAN.R-project.org/package=knitcitations&lt;/a&gt;.&lt;/cite&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;a id=&#39;bib-Oles_2020&#39;&gt;&lt;/a&gt;&lt;a href=&#34;#cite-Oles_2020&#34;&gt;[2]&lt;/a&gt;&lt;cite&gt;
A. Oleś, M. Morgan, and W. Huber.
&lt;em&gt;BiocStyle: Standard styles for vignettes and other Bioconductor documents&lt;/em&gt;.
R package version 2.14.4.
2020.
URL: &lt;a href=&#34;https://github.com/Bioconductor/BiocStyle&#34;&gt;https://github.com/Bioconductor/BiocStyle&lt;/a&gt;.&lt;/cite&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;a id=&#39;bib-Wickham_2019&#39;&gt;&lt;/a&gt;&lt;a href=&#34;#cite-Wickham_2019&#34;&gt;[3]&lt;/a&gt;&lt;cite&gt;
H. Wickham, J. Hester, and W. Chang.
&lt;em&gt;devtools: Tools to Make Developing R Packages Easier&lt;/em&gt;.
R package version 2.2.1.
2019.
URL: &lt;a href=&#34;https://CRAN.R-project.org/package=devtools&#34;&gt;https://CRAN.R-project.org/package=devtools&lt;/a&gt;.&lt;/cite&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;a id=&#39;bib-Xie_2017&#39;&gt;&lt;/a&gt;&lt;a href=&#34;#cite-Xie_2017&#34;&gt;[4]&lt;/a&gt;&lt;cite&gt;
Y. Xie, A. P. Hill, and A. Thomas.
&lt;em&gt;blogdown: Creating Websites with R Markdown&lt;/em&gt;.
ISBN 978-0815363729.
Boca Raton, Florida: Chapman and Hall/CRC, 2017.
URL: &lt;a href=&#34;https://github.com/rstudio/blogdown&#34;&gt;https://github.com/rstudio/blogdown&lt;/a&gt;.&lt;/cite&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reproducibility&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reproducibility&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;## ─ Session info ───────────────────────────────────────────────────────────────────────────────────────────────────────
##  setting  value                       
##  version  R version 3.6.2 (2019-12-12)
##  os       macOS Catalina 10.15.2      
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  ctype    en_US.UTF-8                 
##  tz       America/New_York            
##  date     2020-02-12                  
## 
## ─ Packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────
##  package       * version date       lib source                            
##  assertthat      0.2.1   2019-03-21 [1] CRAN (R 3.6.0)                    
##  backports       1.1.5   2019-10-02 [1] CRAN (R 3.6.0)                    
##  bibtex          0.4.2.2 2020-01-02 [1] CRAN (R 3.6.0)                    
##  BiocManager     1.30.10 2019-11-16 [1] CRAN (R 3.6.1)                    
##  BiocStyle     * 2.14.4  2020-01-09 [1] Bioconductor                      
##  blogdown        0.17    2019-11-13 [1] CRAN (R 3.6.1)                    
##  bookdown        0.17    2020-01-11 [1] CRAN (R 3.6.0)                    
##  callr           3.4.1   2020-01-24 [1] CRAN (R 3.6.2)                    
##  cli             2.0.1   2020-01-08 [1] CRAN (R 3.6.0)                    
##  colorout      * 1.2-1   2019-05-07 [1] Github (jalvesaq/colorout@7ea9440)
##  crayon          1.3.4   2017-09-16 [1] CRAN (R 3.6.0)                    
##  desc            1.2.0   2018-05-01 [1] CRAN (R 3.6.0)                    
##  devtools      * 2.2.1   2019-09-24 [1] CRAN (R 3.6.1)                    
##  digest          0.6.23  2019-11-23 [1] CRAN (R 3.6.0)                    
##  ellipsis        0.3.0   2019-09-20 [1] CRAN (R 3.6.0)                    
##  evaluate        0.14    2019-05-28 [1] CRAN (R 3.6.0)                    
##  fansi           0.4.1   2020-01-08 [1] CRAN (R 3.6.0)                    
##  fs              1.3.1   2019-05-06 [1] CRAN (R 3.6.0)                    
##  glue            1.3.1   2019-03-12 [1] CRAN (R 3.6.0)                    
##  htmltools       0.4.0   2019-10-04 [1] CRAN (R 3.6.0)                    
##  httr            1.4.1   2019-08-05 [1] CRAN (R 3.6.0)                    
##  jsonlite        1.6     2018-12-07 [1] CRAN (R 3.6.0)                    
##  knitcitations * 1.0.10  2019-09-15 [1] CRAN (R 3.6.0)                    
##  knitr           1.27    2020-01-16 [1] CRAN (R 3.6.0)                    
##  lubridate       1.7.4   2018-04-11 [1] CRAN (R 3.6.0)                    
##  magrittr        1.5     2014-11-22 [1] CRAN (R 3.6.0)                    
##  memoise         1.1.0   2017-04-21 [1] CRAN (R 3.6.0)                    
##  pkgbuild        1.0.6   2019-10-09 [1] CRAN (R 3.6.0)                    
##  pkgload         1.0.2   2018-10-29 [1] CRAN (R 3.6.0)                    
##  plyr            1.8.5   2019-12-10 [1] CRAN (R 3.6.0)                    
##  prettyunits     1.1.1   2020-01-24 [1] CRAN (R 3.6.2)                    
##  processx        3.4.1   2019-07-18 [1] CRAN (R 3.6.0)                    
##  ps              1.3.0   2018-12-21 [1] CRAN (R 3.6.0)                    
##  R6              2.4.1   2019-11-12 [1] CRAN (R 3.6.1)                    
##  Rcpp            1.0.3   2019-11-08 [1] CRAN (R 3.6.0)                    
##  RefManageR      1.2.12  2019-04-03 [1] CRAN (R 3.6.0)                    
##  remotes         2.1.0   2019-06-24 [1] CRAN (R 3.6.0)                    
##  rlang           0.4.3   2020-01-24 [1] CRAN (R 3.6.2)                    
##  rmarkdown       2.1     2020-01-20 [1] CRAN (R 3.6.0)                    
##  rprojroot       1.3-2   2018-01-03 [1] CRAN (R 3.6.0)                    
##  sessioninfo     1.1.1   2018-11-05 [1] CRAN (R 3.6.0)                    
##  stringi         1.4.5   2020-01-11 [1] CRAN (R 3.6.0)                    
##  stringr         1.4.0   2019-02-10 [1] CRAN (R 3.6.0)                    
##  testthat        2.3.1   2019-12-01 [1] CRAN (R 3.6.0)                    
##  usethis       * 1.5.1   2019-07-04 [1] CRAN (R 3.6.0)                    
##  withr           2.1.2   2018-03-15 [1] CRAN (R 3.6.0)                    
##  xfun            0.12    2020-01-13 [1] CRAN (R 3.6.0)                    
##  xml2            1.2.2   2019-08-09 [1] CRAN (R 3.6.0)                    
##  yaml            2.2.0   2018-07-25 [1] CRAN (R 3.6.0)                    
## 
## [1] /Library/Frameworks/R.framework/Versions/3.6/Resources/library&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;George Escobar mentioned that they protested the fact that a DUI labeled someone as a criminal, but well, Trump has gone beyond DUIs arrested many individuals with no criminal history.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;George Escobar highlighted that one path of action is to convince local governments to fund/provide lawyers to these individuals.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;I don’t know by how much.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Information has leaked about this but I guess that it’s not completely public info.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Could be with your vote, helping members in your community that are affected, improving how we translate research into terms everyone understands, improving the education about the violent reality many are trying to escape by coming to the US, approaching local governments, etc.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;The app could show the text but also should &lt;em&gt;read&lt;/em&gt; the translations since very young children will very likely not know how to read. I think that the app should never assume that the defendant knows how to read.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Predicting who will win a NFL match at half time</title>
      <link>https://lcolladotor.github.io/2013/03/23/predicting-who-will-win-a-nfl-match-at-half-time/</link>
      <pubDate>Sat, 23 Mar 2013 00:00:00 +0000</pubDate>
      <guid>https://lcolladotor.github.io/2013/03/23/predicting-who-will-win-a-nfl-match-at-half-time/</guid>
      <description>&lt;p&gt;It was great to have a little break, &lt;em&gt;Spring break&lt;/em&gt;, although the weather didn&amp;#8217;t feel like spring at all! During the early part of the break I worked on my final project for Jeff Leek&amp;#8217;s data analysis class, which we call 140.753 here. Continuing &lt;a href=&#34;http://fellgernon.tumblr.com/tagged/jhsph753#.UU44Y1vF2c4&#34;&gt;my previous posts on the topic&lt;/a&gt;, this time I&amp;#8217;ll share the results of my final project.&lt;/p&gt;
&lt;p&gt;At the beginning of the course, we had to submit a project plan (more like a proposal) and &lt;a href=&#34;https://github.com/lcolladotor/lcollado753/blob/master/hw/projectplan/lcollado_projectplan.pdf&#34;&gt;in mine&lt;/a&gt; I announced my interest to look into some sports data. At the time I included a few links to Brian Burke&amp;#8217;s Advanced NFL Stats site (&lt;span class=&#34;showtooltip&#34; title=&#34;(2013). Advanced NFL Stats.   http://www.advancednflstats.com/ [Online. last-accessed:  2013-03-23 23:28:38].  http://www.advancednflstats.com/.&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/&#34;&gt;Burke&lt;/a&gt;&lt;/span&gt;). At the time I didn&amp;#8217;t know that Burke&amp;#8217;s site described in detail a lot of the information I would end up using.&lt;/p&gt;
&lt;p&gt;My final project had to do with splitting NFL games by half and then use only the play-by-play data from the first half to predict if team A or B would win the game. My overall goal was to have some fun with sports data which I had never looked at, but then also try to come up with something I would personally use in the future. So, why split games by half? I personally would like to know if I should keep watching a game or not at half time. Having a tool to help me decide would be great, and well, if the team I&amp;#8217;m rooting for has high chances of losing or winning, ideally I would switch to doing something else. A related question that I didn&amp;#8217;t try to answer is which half is worth watching? This would be a meaningful question if you only have time to watch one of them.&lt;/p&gt;
&lt;p&gt;To truly satisfy my goals, it wasn&amp;#8217;t enough to just build a predictive model. That is why I also built a web application using the &lt;code&gt;shiny&lt;/code&gt; package (&lt;span class=&#34;showtooltip&#34; title=&#34;RStudio and Inc. (2013). _shiny: Web Application Framework for R_.  R package version 0.4.0,   http://CRAN.R-project.org/package=shiny.&#34;&gt;&lt;a href=&#34;http://CRAN.R-project.org/package=shiny&#34;&gt;RStudio and Inc., 2013&lt;/a&gt;&lt;/span&gt;). It was the first time I did a shiny app, but thanks to the good manual and some examples on GitHub from John Muschelli like his &lt;a href=&#34;https://github.com/muschellij2/Shiny_model&#34;&gt;Shiny_model&lt;/a&gt; it wasn&amp;#8217;t so bad. I thus invite you to test and browse my shiny app at &lt;a href=&#34;http://glimmer.rstudio.com/lcolladotor/NFLhalf/&#34;&gt;&lt;a href=&#34;http://glimmer.rstudio.com/lcolladotor/NFLhalf/&#34;&gt;http://glimmer.rstudio.com/lcolladotor/NFLhalf/&lt;/a&gt;&lt;/a&gt;. It could be improved by adding some functions that scrape live data for the 2013 season so you don&amp;#8217;t have to input all the variables needed by using the sliders. Anyhow, I&amp;#8217;m happy with the result.&lt;/p&gt;
&lt;p&gt;The entire project&amp;#8217;s code, EDA steps, shiny app, and report are available via GitHub in my repository (&lt;span class=&#34;showtooltip&#34; title=&#34;lcolladotor (2013). lcollado753.   https://github.com/lcolladotor/lcollado753 [Online.  last-accessed: 2013-03-21 02:23:49].   https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half.&#34;&gt;&lt;a href=&#34;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&#34;&gt;lcollado753&lt;/a&gt;&lt;/span&gt;). While the details are in the report, I&amp;#8217;ll give a brief summary here.&lt;/p&gt;
&lt;p&gt;Basically, I summarized the play-by-play data for all NFL games from 2002 to 2012 seasons as provided by Burke (&lt;span class=&#34;showtooltip&#34; title=&#34;(2010). Advanced NFL Stats: Play-by-Play Data.   http://www.advancednflstats.com/2010/04/play-by-play-data.html  [Online. last-accessed: 2013-03-24 00:08:20].   http://www.advancednflstats.com/2010/04/play-by-play-data.html.&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2010/04/play-by-play-data.html&#34;&gt;Burke, 2010&lt;/a&gt;&lt;/span&gt;). I used some of the variables Burke uses (&lt;span class=&#34;showtooltip&#34; title=&#34;(2009). Advanced NFL Stats: How the Model Works-A Detailed  Example Part 1.   http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html  [Online. last-accessed: 2013-03-24 00:08:21].   http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html.&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html&#34;&gt;Burke, 2009&lt;/a&gt;&lt;/span&gt;) and some others like the score difference, who starts the second half, and the game day winning percentages of both teams. After exploring the data, I discarded the years 2002 to 2005. Then, I trained a model using the 2006 to 2011 data and did some quick model selection. Note that I&amp;#8217;m not doing the adjustment by opponent the way Burke did it (&lt;span class=&#34;showtooltip&#34; title=&#34;(2009). Advanced NFL Stats: How the Model Works-A Detailed  Example Part 2.   http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html  [Online. last-accessed: 2013-03-24 00:08:23].   http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html.&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html&#34;&gt;Burke, 2009-2&lt;/a&gt;&lt;/span&gt;) in part because I was running out of time, but also because the model already uses the current game winning percentages of both teams to consider the two team&amp;#8217;s strength. I evaluated the model using the 2012 data and after seeing that it worked decently enough, I trained a second model using the data from 2006 to 2012 so it can be used for the 2013 season. These two trained models are the ones available in the shiny app I made.&lt;/p&gt;
&lt;p&gt;In the report, I didn&amp;#8217;t include ROCs—a big miss—so here they go. The code I will show below is heavily based on a post on GLMs (&lt;span class=&#34;showtooltip&#34; title=&#34;denishaine (2013). Veterinary Epidemiologic Research: GLM  \ Evaluating Logistic Regression Models (part 3).   http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/  [Online. last-accessed: 2013-03-23 22:51:49].   http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/.&#34;&gt;&lt;a href=&#34;http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/&#34;&gt;denishaine, 2013&lt;/a&gt;&lt;/span&gt;). The code below is written in a way that you can easily reproduce it if you have cloned my repository for the 140.753 class (&lt;span class=&#34;showtooltip&#34; title=&#34;lcolladotor (2013). lcollado753.   https://github.com/lcolladotor/lcollado753 [Online.  last-accessed: 2013-03-21 02:23:49].   https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half.&#34;&gt;&lt;a href=&#34;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&#34;&gt;lcollado753&lt;/a&gt;&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;First, some setup steps.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Specify the directory where you cloned the lcollado753 repo
maindir &amp;lt;- &amp;quot;whereYouClonedTheRepo&amp;quot;
## Load packages needed
suppressMessages(library(ROCR))
library(ggplot2)

## Load fits.
## Remember that 1st one used data from 2006 to 2011
## and the 2nd one used data from 2006 to 2012.
load(paste0(maindir, &amp;quot;/lcollado753/final/nfl_half/EDA/model/fits.Rdata&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I make the ROCs for both trained models using the data that they were trained on. They should be quite good since it uses the same data to build the model that it will then try to predict.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Make the ROC plots

## Simple list where I&#39;ll store all the results so I can compare the ROC plots later on
all &amp;lt;- list()

## Construct prediction function
for(i in 1:2) {
	## Predict on the original data
	pred &amp;lt;- predict(fits[[i]])
	
	## Subset original data (remove NA&#39;s)
	data &amp;lt;- fits[[i]]$data
	data &amp;lt;- data[complete.cases(data),]
	
	## Construct prediction function
	pred.fn &amp;lt;- prediction(pred, data$win)
	
	## Get performance info
	perform &amp;lt;- performance(pred.fn, &amp;quot;tpr&amp;quot;, &amp;quot;fpr&amp;quot;)
	
	## Get ready to plot
	toPlot &amp;lt;- data.frame(tpr = unlist(slot(perform, &amp;quot;y.values&amp;quot;)), fpr = unlist(slot(perform, &amp;quot;x.values&amp;quot;)))
	all &amp;lt;- c(all, list(toPlot))

	## Make the plot
	res &amp;lt;- ggplot(toPlot) + geom_line(aes(x=fpr, y=tpr)) + geom_abline(intercept=0, slope=1, colour=&amp;quot;orange&amp;quot;) + ylab(&amp;quot;Sensitivity&amp;quot;) + xlab(&amp;quot;1 - Specificity&amp;quot;) + ggtitle(paste(&amp;quot;Years 2006 to&amp;quot;, c(&amp;quot;2011&amp;quot;, &amp;quot;2012&amp;quot;)[i]))
	print(res)
	
	## Print the AUC value
	print(unlist(performance(pred.fn, &amp;quot;auc&amp;quot;)@y.values))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&#34;plot of chunk ROC&#34; src=&#34;http://i.imgur.com/b1FS2ml.png&#34;/&gt;&lt;/p&gt;
```r
## [1] 0.8506
```
&lt;p&gt;&lt;img alt=&#34;plot of chunk ROC&#34; src=&#34;http://i.imgur.com/f2UOySy.png&#34;/&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## [1] 0.8513
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Both ROC plots look pretty similar (well, the data sets are very similar!) and have relatively high AUC values.&lt;/p&gt;
&lt;p&gt;Next, I make the ROC plot using the model trained with the data from 2006 to 2011 to predict the outcomes for the 2012 games.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Load 2012 data
load(paste0(maindir, &amp;quot;/lcollado753/final/nfl_half/data/pred/info2012.Rdata&amp;quot;))

## Predict using model fit with data from 2006 to 2011
pred &amp;lt;- predict(fits[[1]], info2012)

## Construction prediction function
pred.fn &amp;lt;- prediction(pred, info2012$win)

## Get performance info
perform &amp;lt;- performance(pred.fn, &amp;quot;tpr&amp;quot;, &amp;quot;fpr&amp;quot;)

## Get ready to plot
toPlot &amp;lt;- data.frame(tpr = unlist(slot(perform, &amp;quot;y.values&amp;quot;)), fpr = unlist(slot(perform, &amp;quot;x.values&amp;quot;)))
all &amp;lt;- c(all, list(toPlot))

## Make the plot
ggplot(toPlot) + geom_line(aes(x=fpr, y=tpr)) + geom_abline(intercept=0, slope=1, colour=&amp;quot;orange&amp;quot;) + ylab(&amp;quot;Sensitivity&amp;quot;) + xlab(&amp;quot;1 - Specificity&amp;quot;) + ggtitle(&amp;quot;Model trained 2006-2011 predicting 2012&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&#34;plot of chunk pred2012&#34; src=&#34;http://i.imgur.com/DDcsW7W.png&#34;/&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Print the AUC value
print(unlist(performance(pred.fn, &amp;quot;auc&amp;quot;)@y.values))
## [1] 0.816
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The steps in the curve are more visible since it is using less data. It also seems to be a little less good than the other two, as expected. This is clear when comparing the AUC values.&lt;/p&gt;
&lt;p&gt;Finally, I plot all curves in the same picture to visually compare them.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;names(all) &amp;lt;- c(&amp;quot;train2011&amp;quot;, &amp;quot;train2012&amp;quot;, &amp;quot;pred2012&amp;quot;)
for(i in 1:3) {
	all[[i]] &amp;lt;- cbind(all[[i]], rep(names(all)[i], nrow(all[[i]])))
	colnames(all[[i]])[3] &amp;lt;- &amp;quot;set&amp;quot;
}
all &amp;lt;- do.call(rbind, all)

ggplot(all) + geom_line(aes(x=fpr, y=tpr, colour=set)) + geom_abline(intercept=0, slope=1, colour=&amp;quot;orange&amp;quot;) + ylab(&amp;quot;Sensitivity&amp;quot;) + xlab(&amp;quot;1 - Specificity&amp;quot;) + ggtitle(&amp;quot;Comparing ROCs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&#34;plot of chunk allInOne&#34; src=&#34;http://i.imgur.com/tUVfgfs.png&#34;/&gt;&lt;/p&gt;
&lt;p&gt;Both ROCs with the trained data (train2011, train2012) are nearly identical and both are slightly superior to the one predicting the 2012 games.&lt;/p&gt;
&lt;p&gt;Overall I am happy with the results and while some things can certainly be improved, I look forward to the NFL 2013 season. Also, remember that Burke publishes his winning estimated probabilities from week 4 onward (&lt;span class=&#34;showtooltip&#34; title=&#34;BURKE BB (2013). Brian Burke - The Fifth Down Blog -  NYTimes.com.   http://fifthdown.blogs.nytimes.com/author/brian-burke/ [Online.  last-accessed: 2013-03-24 00:26:32].   http://fifthdown.blogs.nytimes.com/author/brian-burke/.&#34;&gt;&lt;a href=&#34;http://fifthdown.blogs.nytimes.com/author/brian-burke/&#34;&gt;The Fifth Down Blog&lt;/a&gt;&lt;/span&gt;). So you might be interested on comparing the probability at half time versus his estimated probability which is calculated before the game starts. I mean, maybe you could use the difference between the two to have an idea of how unexpected the first half was. After all, if a game falls outside the pattern it might be worth watching.&lt;/p&gt;
&lt;p&gt;Citations made with &lt;code&gt;knitcitations&lt;/code&gt; (&lt;span class=&#34;showtooltip&#34; title=&#34;Boettiger C (2013). _knitcitations: Citations for knitr markdown  files_. R package version 0.4-4,   https://github.com/cboettig/knitcitations.&#34;&gt;&lt;a href=&#34;https://github.com/cboettig/knitcitations&#34;&gt;Boettiger, 2013&lt;/a&gt;&lt;/span&gt;).&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;lcolladotor, lcollado753. &lt;em&gt;GitHub&lt;/em&gt; &lt;a href=&#34;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&#34;&gt;&lt;a href=&#34;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&#34;&gt;https://github.com/lcolladotor/lcollado753/tree/master/final/nfl_half&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;denishaine, (2013) Veterinary Epidemiologic Research: GLM &amp;amp;ndash; Evaluating Logistic Regression Models (part 3). &lt;em&gt;denis haine&lt;/em&gt; &lt;a href=&#34;http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/&#34;&gt;&lt;a href=&#34;http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/&#34;&gt;http://denishaine.wordpress.com/2013/03/19/veterinary-epidemiologic-research-glm-evaluating-logistic-regression-models-part-3/&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Advanced NFL Stats. &lt;a href=&#34;http://www.advancednflstats.com/&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/&#34;&gt;http://www.advancednflstats.com/&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(2010) Advanced NFL Stats: Play-by-Play Data. &lt;a href=&#34;http://www.advancednflstats.com/2010/04/play-by-play-data.html&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2010/04/play-by-play-data.html&#34;&gt;http://www.advancednflstats.com/2010/04/play-by-play-data.html&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(2009) Advanced NFL Stats: How the Model Works–A Detailed Example Part 1. &lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html&#34;&gt;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example.html&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(2009) Advanced NFL Stats: How the Model Works–A Detailed Example Part 2. &lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html&#34;&gt;&lt;a href=&#34;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html&#34;&gt;http://www.advancednflstats.com/2009/01/how-model-works-detailed-example-part-2.html&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;By BURKE, Brian Burke - The Fifth Down Blog - NYTimes.com. &lt;em&gt;The Fifth Down Â» Brian Burke&lt;/em&gt; &lt;a href=&#34;http://fifthdown.blogs.nytimes.com/author/brian-burke/&#34;&gt;&lt;a href=&#34;http://fifthdown.blogs.nytimes.com/author/brian-burke/&#34;&gt;http://fifthdown.blogs.nytimes.com/author/brian-burke/&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Carl Boettiger, knitcitations: Citations for knitr markdown files. &lt;a href=&#34;https://github.com/cboettig/knitcitations&#34;&gt;&lt;a href=&#34;https://github.com/cboettig/knitcitations&#34;&gt;https://github.com/cboettig/knitcitations&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;RStudio , Inc. , (2013) shiny: Web Application Framework for R. &lt;a href=&#34;http://CRAN.R-project.org/package=shiny&#34;&gt;&lt;a href=&#34;http://CRAN.R-project.org/package=shiny&#34;&gt;http://CRAN.R-project.org/package=shiny&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
