"xn----ieuycya4cyb1b7jwa4fc8h4718bnq8c.com",
"xn----ny6a58fr8c8rtpsucir8k1bo62a.net",
"xn----peurf0asz4dzaln0qm161er8pd.biz",
"xn----twfb7ei8dwjzbf9dg.com",
"xn----ymcabp2br3mk93k.com")
intnl_doms <- c("ثبت-دومین.com",
"טיול-לפיליפינים.net",
"бизнес-тренер.com",
"новый-год.com",
"東京ライブ-バルーンスタンド.com",
"看護師高収入-求人.net",
"ユベラ-贅沢ポリフェノール.biz",
"เด็ก-ภูเก็ต.com",
"ایران-هاست.com")
for_valid <- c("gr€€n.no", "זגורי-אימפריה-לצפייה-ישירה.net", "ثبت-دومین.com",
"טיול-לפיליפינים.net", "xn------qpeiobbci9acacaca2c8a6ie7b9agmy.net", "xn----0mcgcx6kho30j.com",
"xn----9hciecaaawbbp1b1cd.net", "rudis.net")
# encoding
puny_encode(ascii_doms)
##  [1] "זגורי-אימפריה-לצפייה-ישירה.net"  "ثبت-دومین.com"                   "טיול-לפיליפינים.net"
##  [4] "бизнес-тренер.com"               "новый-год.com"                   "東京ライブ-バルーンスタンド.com"
##  [7] "看護師高収入-求人.net"           "ユベラ-贅沢ポリフェノール.biz"   "เด็ก-ภูเก็ต.com"
## [10] "ایران-هاست.com"
# decoding
puny_decode(intnl_doms)
## [1] "xn----0mcgcx6kho30j.com"                   "xn----9hciecaaawbbp1b1cd.net"
## [3] "xn----9sbmbaig5bd2adgo.com"                "xn----ctbeewwhe7i.com"
## [5] "xn----ieuycya4cyb1b7jwa4fc8h4718bnq8c.com" "xn----ny6a58fr8c8rtpsucir8k1bo62a.net"
## [7] "xn----peurf0asz4dzaln0qm161er8pd.biz"      "xn----twfb7ei8dwjzbf9dg.com"
## [9] "xn----ymcabp2br3mk93k.com"
# validation
puny_tld_check(for_valid)
##
symbols <- c("AFK", "ASHR", "ECH", "EGPT",
"EIDO", "EIRL", "EIS", "ENZL",
"EPHE", "EPI", "EPOL", "EPU",
"EWA", "EWC", "EWD", "EWG",
"EWH", "EWI", "EWJ", "EWK",
"EWL", "EWM", "EWN", "EWO",
"EWP", "EWQ", "EWS", "EWT",
"EWU", "EWW", "EWY", "EWZ",
"EZA", "FM", "FRN", "FXI",
"GAF", "GULF", "GREK", "GXG",
"IDX", "MCHI", "MES", "NORW",
"QQQ", "RSX", "THD", "TUR",
"VNM", "TLT"
)
getSymbols(symbols, from = "2003-01-01")
prices <- list()
entryRets <- list()
for(i in 1:length(symbols)) {
prices[[i]] <- Ad(get(symbols[i]))
}
prices <- do.call(cbind, prices)
colnames(prices) <- gsub("\\.[A-z]*", "", colnames(prices))
returns <- Return.calculate(prices)
returns <- returns[-1,]
sumIsNa <- function(col) {
return(sum(is.na(col)))
}
library(quantmod)
install.packages(quantmod)
install.packages('quantmod'')
'
install.packages('quantmod')
library(quantmod)
symbols <- c("AFK", "ASHR", "ECH", "EGPT",
"EIDO", "EIRL", "EIS", "ENZL",
"EPHE", "EPI", "EPOL", "EPU",
"EWA", "EWC", "EWD", "EWG",
"EWH", "EWI", "EWJ", "EWK",
"EWL", "EWM", "EWN", "EWO",
"EWP", "EWQ", "EWS", "EWT",
"EWU", "EWW", "EWY", "EWZ",
"EZA", "FM", "FRN", "FXI",
"GAF", "GULF", "GREK", "GXG",
"IDX", "MCHI", "MES", "NORW",
"QQQ", "RSX", "THD", "TUR",
"VNM", "TLT"
)
getSymbols(symbols, from = "2003-01-01")
prices <- list()
entryRets <- list()
for(i in 1:length(symbols)) {
prices[[i]] <- Ad(get(symbols[i]))
}
prices <- do.call(cbind, prices)
colnames(prices) <- gsub("\\.[A-z]*", "", colnames(prices))
returns <- Return.calculate(prices)
returns <- returns[-1,]
sumIsNa <- function(col) {
return(sum(is.na(col)))
}
library(portfolioAnalytics)
install.packages('portfolioAnalytics')
install.packages('PortfolioAnalytics')
library(PortfolioAnalytics)
returns <- Return.calculate(prices)
returns <- returns[-1,]
sumIsNa <- function(col) {
return(sum(is.na(col)))
}
appendZeroes <- function(selected, originalSetNames) {
zeroes <- rep(0, length(originalSetNames) - length(selected))
names(zeroes) <- originalSetNames[!originalSetNames %in% names(selected)]
all <- c(selected, zeroes)
all <- all[originalSetNames]
return(all)
}
computeStats <- function(rets) {
stats <- rbind(table.AnnualizedReturns(rets), maxDrawdown(rets), CalmarRatio(rets))
return(round(stats, 3))
}
CLAAbacktest <- function(returns, lookback = 3, volThresh = .1, assetCaps = .5, tltCap = 1,
returnWeights = FALSE, useTMF = FALSE) {
if(useTMF) {
returns$TLT <- returns$TLT * 3
}
ep <- endpoints(returns, on = "months")
weights <- list()
for(i in 2:(length(ep) - lookback)) {
retSubset <- returns[(ep[i]+1):ep[i+lookback],]
retNAs <- apply(retSubset, 2, sumIsNa)
validRets <- retSubset[, retNAs==0]
retForecast <- Return.cumulative(validRets)
covRets <- cov(validRets)
weightLims <- rep(assetCaps, ncol(covRets))
weightLims[colnames(covRets)=="TLT"] <- tltCap
weight <- CCLA(covMat = covRets, retForecast = retForecast, weightLimit = weightLims, volThresh = volThresh)
weight <- weight[[2]][,5:ncol(weight[[2]])]
weight <- appendZeroes(selected = weight, colnames(retSubset))
weight <- xts(t(weight), order.by=last(index(validRets)))
weights[[i]] <- weight
}
weights <- do.call(rbind, weights)
stratRets <- Return.portfolio(R = returns, weights = weights)
if(returnWeights) {
return(list(weights, stratRets))
}
return(stratRets)
}
xx <- . %>% is.na %>% sum
ls ()
?endpoints
x <- read_csv('https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv')
library(tidyr)
x <- read_csv(https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv)
x <- read_csv('https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv')
x <- tbl_df(read.csv('https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv') )
x <- tbl_df(read.csv('http://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv') )
con = url('https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv', method = 'libcurl')
str(x = read.csv(con))
con
con = url('https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv', method = 'libcurl')
con
'https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse; .} ->
x
'https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
( glimpse; .) ->
x
'https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
( glimpse(.); .) ->
x
'https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse(.); . } ->
x
'https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df
'https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl')
'https://github.com/fivethirtyeight/data/blob/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv
#   use a url() connection with the libcurl method
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse; .} ->
x
#   use a url() connection with the libcurl method
'#   use a url() connection with the libcurl method
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse(.); .} ->
x
#   use a url() connection with the libcurl method
'#   use a url() connection with the libcurl method
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse(.); .} ->
x
install.packages("portfolio")
library(portfolio)
#edit(vignette('matching'))
vignette(package = 'matching')
vignette(package = 'portfolio')
edit(vignette('matching_portfolio', package = 'portfolio'))
edit(vignette('matching_portfolio', package = 'portfolio'))
op <- options(width = 80, digits = 2, scipen = 5)
###################################################
### code chunk number 2: matching_portfolio.Rnw:72-73
###################################################
library(portfolio)
###################################################
### code chunk number 3: matching_portfolio.Rnw:76-79
###################################################
data(assay)
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse; .} ->
x
str(x)
rm(x)
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse; .} ->
x
str(x)
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse(.) ; .} ->
x
rm(x)
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse(.) ; .} ->
x
data(assay)
assay[c(1407, 1873, 1058, 2453, 1833, 1390), c("id", "symbol", "name", "country",
"currency", "price", "sector", "liq", "on.fl", "ret.0.3.m", "ret.0.6.m")]
assay$assay.wt <- ifelse(assay$on.fl, -1, NA)
glimpse(assay)
assay[c(1407, 1873, 1058, 2453, 1833, 1390),
c("id", "symbol", "name", "country",
"currency", "price", "sector", "liq", "on.fl", "ret.0.3.m", "ret.0.6.m")]
assay$assay.wt <- ifelse(assay$on.fl, -1, NA)
p <- new("portfolioBasic",
name    = "AFL Portfolio",
instant = as.Date("2004-12-31"),
data    = assay,
id.var  = "symbol",
in.var  = "assay.wt",
size    = "all",
ret.var = "ret.0.3.m")
type    = "relative",
summary(p)
p <- new("portfolioBasic",
name    = "AFL Portfolio",
instant = as.Date("2004-12-31"),
data    = assay,
id.var  = "symbol",
in.var  = "assay.wt",
type    = "relative",
size    = "all",
ret.var = "ret.0.3.m")
summary(p)
summarise(assay$on.fl)
summary(performance(p))
exposure(p, exp.var = 'sector')
p.m <- matching(p, covariates = c("country", "sector", "liq"))
summary(p.m)
p@weights$id
p@weights
p
!p.m@matches
p.m@matches
all(!p.m@matches[,1] %in% p@weights$id)
exposure(p, exp.var = "sector")
exposure(p.m, exp.var = "sector")
exposure(p, exp.var = "liq")
exposure(p.m, exp.var = "liq")
summary(performance(p.m))
options(op)
vignette(package = 'portfolio')
edit(vignette('portfolio', package = 'portfolio'))
library(portfolio)
data(dow.jan.2005)
summary(dow.jan.2005)
head(dow.jan.2005)
options(digits = 3)
p <- new("portfolioBasic",
instant = as.Date("2004-12-31"),
id.var  = "symbol",
in.var  = "price",
sides   = "long",
ret.var = "month.ret",
data    = dow.jan.2005)
summary(p)
exposure(p, exp.var = c("price", "sector"))
performance(p)
contribution(p, contrib.var = c("sector"))
contribution(p, contrib.var = c("cap.bil"))
p <- new("portfolioBasic",
instant = as.Date("2004-12-31"),
id.var  = "symbol",
in.var  = "price",
type    = "linear",
sides   = c("long", "short"),
ret.var = "month.ret",
data    = dow.jan.2005)
summary(p)
plot(p)
exposure(p, exp.var = c("price", "sector"))
plot(exposure(p, exp.var = c("price", "sector")))
performance(p)
contribution(p, contrib.var = c("cap.bil", "sector"))
plot(contribution(p, contrib.var = c("cap.bil", "sector")))
options(op)
library('devtools')
install_github("SciDBR","paradigm4",quick=TRUE)
library(scidb)
?scidb
packageDescription('scidb')
scidbconnect()
scidblist
scidblist()
scidbconnect()
scidbconnect
scidbdisconnect()
debug(scidbconnect)
scidbconnect()
scidbquery(query = "setopt('precision','16')", release = 1,
resp = TRUE, stream = 0L)
scidb:::scidbquery(query = "setopt('precision','16')", release = 1,
resp = TRUE, stream = 0L)
library(monet)
library(MonetDB.R)
vignette(package = 'MonetDB.R')
# write some test data
data(iris)
dbWriteTable(conn, "iris", iris)
# read data by SQL query
ds1 <- dbGetQuery(conn,"SELECT avg(sepal_width) FROM iris")
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/demo")
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/voc")
# write some test data
data(iris)
dbWriteTable(conn, "iris", iris)
# read data by SQL query
ds1 <- dbGetQuery(conn,"SELECT avg(sepal_width) FROM iris")
# write some test data
data(iris)
dbWriteTable(conn, "iris", iris, overwrite = TRUE)
# read data by SQL query
ds1 <- dbGetQuery(conn,"SELECT avg(sepal_width) FROM iris")
https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv'
# https://github.com/hadley/bigrquery
library(bigrquery)
project <- c("avid-atrium-91611", "1005431568862")
options("httr_oob_default" = TRUE)
c("SELECT * FROM [publicdata:samples.gsod]
WHERE max_sustained_wind_speed IS NOT NULL AND max_sustained_wind_speed > 96
LIMIT 1000")
sql <- c(
"SELECT year, month, day, weight_pounds FROM [publicdata:samples.natality] LIMIT 5",
"SELECT title,contributor_username, comment FROM [publicdata:samples.wikipedia]
WHERE title CONTAINS 'beer' LIMIT 100;")[1]
system.time(df <- query_exec(sql, project = project))
str(df)
install.packages("bigrquery")
# https://github.com/hadley/bigrquery
library(bigrquery)
project <- c("avid-atrium-91611", "1005431568862")
options("httr_oob_default" = TRUE)
c("SELECT * FROM [publicdata:samples.gsod]
WHERE max_sustained_wind_speed IS NOT NULL AND max_sustained_wind_speed > 96
LIMIT 1000")
sql <- c(
"SELECT year, month, day, weight_pounds FROM [publicdata:samples.natality] LIMIT 5",
"SELECT title,contributor_username, comment FROM [publicdata:samples.wikipedia]
WHERE title CONTAINS 'beer' LIMIT 100;")[1]
system.time(df <- query_exec(sql, project = project))
str(df)
# https://github.com/hadley/bigrquery
library(bigrquery)
project <- c("avid-atrium-91611", "1005431568862")
options("httr_oob_default" = TRUE)
sql <- c(
"SELECT year, month, day, weight_pounds FROM [publicdata:samples.natality] LIMIT 5",
"SELECT title,contributor_username, comment FROM [publicdata:samples.wikipedia]
WHERE title CONTAINS 'beer' LIMIT 100;")[1]
system.time(df <- query_exec(sql, project = project))
str(df)
library(dplyr)
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
read.csv %>%
{glimpse(.) ; .} %>%
tbl_df ->
x
str(x)
?read_csv
library(tidyr)
read_csv
?read.csv
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
read_csv %>% head
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
url %>%
read_csv %>% head
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
read.csv %>% head
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
url %>%
read.csv %>% head
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
url %>%
read.csv
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse(.) ; .} ->
x
str(x)
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
url(method = 'libcurl')
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
url(method = 'libcurl') %>%
read.csv
'https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv' %>%
url(method = 'libcurl')
ur('https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv')
url('https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv')
url('https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv')
url('https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv', method = 'libcurl')
url('https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv', method = 'libcurl') %>%
url('https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv', method = 'libcurl') %>%
''
url('https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv', method = 'libcurl') %>%
read.csv %>%
head
url('https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv', method = 'libcurl') %>%
read.csv
x <- rl('https://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2011-ausopen-points.csv', method = 'libcurl') %>%
read.csv
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ glimpse(.) ; .} ->
x
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
tbl_df %>%
{ print(glimpse(.) ; .} ->
x
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
{ print(glimpse(.) ; .} ->
x
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
{ print(glimpse(.) ; .} ->
x
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv %>%
{ print(glimpse(.)) ; .} ->
x
str(x)
'https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv' %>%
url(method = 'libcurl') %>%
read.csv ->
x
str(x)
read.csv('https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv)
str(x)
''
'
'
'
read.csv('https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv')
read.csv('https://raw.githubusercontent.com/fivethirtyeight/data/master/tennis-time/serve_times.csv')
ds1 <- dbGetQuery(conn,"SELECT avg(sepal_width) FROM iris")
conn
library(WikipediR)
archy_cat <- pages_in_category("en", "wikipedia", categories = "Archaeological_artifacts")
length(archy_cat$query$categorymembers)
[1] 10
sapply(archy_cat$query$categorymember, function(i) i$title)
install.packages(c("WikipediR", "WikipediaR", "WikidataR"))
