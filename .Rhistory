url(method = 'libcurl') %>%
fread -> xx
'http://raw.githubusercontent.com/JeffSackmann/tennis_slam_pointbypoint/master/2015-ausopen-matches.csv' %>%
url(method = 'libcurl') %>%
read.csv -> xx
str(xx)
dbWriteTable(conn, "2015-ausopen-matches", xx)
"x2015-ausopen-matches" <- xx
dbWriteTable(conn, x2015-ausopen-matches, x2015-ausopen-matches)
x2015-ausopen-matches <- xx
str(xx)
x2015_ausopen_matches <- xx
dbWriteTable(conn, x2015_ausopen_matches, x2015_ausopen_matches)
str(x2015_ausopen_matches)
str(iris)
conn
dbWriteTable(conn, "x2015_ausopen_matches", x2015_ausopen_matches)
?dbWriteTable
con <- dbConnect(RSQLite::SQLite(), ":memory:")
dbWriteTable(con, "x2015_ausopen_matches", x2015_ausopen_matches)
dbReadTable(con, "mtcars")
str(dbReadTable(con, "x2015_ausopen_matches"))
?dbConnect
library(devtools)
library(httr)
library(lubridate)
install_github('zatonovo/odessa')
library(odessa)
library(forecast)
url <- "http://api.panoptez.ml/v1/twitter/query/timeline/3.json?start=2015-06-04&stop=2015-06-04&app_id=APP_ID&app_key=APP_KEY"
response <- GET(url)
raw <- content(response)
raw
response
raw
url <- "http://api.panoptez.ml/v1/twitter/query/timeline/3.json?start=2015-06-04&stop=2015-06-04&app_id=APP_ID&app_key=APP_KEY"
response <- GET(url)
raw <- content(response)
raw
url <- "http://api.panoptez.ml/v1/twitter/query/timeline/3.json?start=2015-06-04&stop=2015-06-04&app_id=APP_ID&app_key=APP_KEY"
response <- GET(url)
raw <- content(response)
raw
url <- "http://api.panoptez.ml/v1/twitter/query/timeline/3.json?start=2015-06-04&stop=2015-06-04&app_id=APP_ID&app_key=APP_KEY"
response <- GET(url)
raw <- content(response)
APP_ID = 'f45d58da'
APP_KEY = '8d2c446cb5be8beddb8f48719f7fbd13'
url <- "http://api.panoptez.ml/v1/twitter/query/timeline/3.json?start=2015-06-04&stop=2015-06-04&app_id=APP_ID&app_key=APP_KEY"
response <- GET(url)
raw <- content(response)
raw
url <- "http://api.panoptez.ml/v1/twitter/query/timeline/3.json?start=2015-06-04&stop=2015-06-04&app_id=f45d58da&app_key=8d2c446cb5be8beddb8f48719f7fbd13"
response <- GET(url)
raw <- content(response)
raw
url
library(Rbitcoin)
## Loading required package: data.table
## You are currently using Rbitcoin 0.9.2, be aware of the changes coming in the next releases (0.9.3 - github, 0.9.4 - cran). Do not auto update Rbitcoin to 0.9.3 (or later) without testing. For details see github.com/jangorecki/Rbitcoin. This message will be removed in 0.9.5 (or later).
wait <- antiddos(market = 'kraken', antispam_interval = 5, verbose = 1)
market.api.process('kraken',c('BTC','EUR'),'ticker')
##    market base quote           timestamp market_timestamp  last     vwap
## 1: kraken  BTC   EUR 2015-01-02 13:12:03             <NA&gt; 263.2 262.9169
##      volume    ask    bid
## 1: 458.3401 263.38 263.22
The function antiddos makes sure that you’re not overusing the Bitcoin API. A reasonable query interval should be one query every 10s.
Here’s a second example that gives you a time-series of the lastest exchange values:
trades <- market.api.process('kraken',c('BTC','EUR'),'trades')
Rbitcoin.plot(trades, col='blue')
install.packages("Rbitcoin")
library(Rbitcoin)
## Loading required package: data.table
## You are currently using Rbitcoin 0.9.2, be aware of the changes coming in the next releases (0.9.3 - github, 0.9.4 - cran). Do not auto update Rbitcoin to 0.9.3 (or later) without testing. For details see github.com/jangorecki/Rbitcoin. This message will be removed in 0.9.5 (or later).
wait <- antiddos(market = 'kraken', antispam_interval = 5, verbose = 1)
market.api.process('kraken',c('BTC','EUR'),'ticker')
##    market base quote           timestamp market_timestamp  last     vwap
## 1: kraken  BTC   EUR 2015-01-02 13:12:03             <NA&gt; 263.2 262.9169
##      volume    ask    bid
## 1: 458.3401 263.38 263.22
The function antiddos makes sure that you’re not overusing the Bitcoin API. A reasonable query interval should be one query every 10s.
Here’s a second example that gives you a time-series of the lastest exchange values:
trades <- market.api.process('kraken',c('BTC','EUR'),'trades')
Rbitcoin.plot(trades, col='blue')
wallet <- blockchain.api.process('15Mb2QcgF3XDMeVn6M7oCG6CQLw4mkedDi')
seed <- '1NfRMkhm5vjizzqkp2Qb28N7geRQCa4XqC'
genesis <- '1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa'
singleaddress <- blockchain.api.query(method = 'Single Address', bitcoin_address = seed, limit=100)
txs <- singleaddress$txs
bc <- data.frame()
for (t in txs) {
hash <- t$hash
for (inputs in t$inputs) {
from <- inputs$prev_out$addr
for (out in t$out) {
to <- out$addr
va <- out$value
bc <- rbind(bc, data.frame(from=from,to=to,value=va, stringsAsFactors=F))
}
}
}
After downloading and transforming the blockchain data, we’re now aggregating the resulting transaction table on address level:
library(plyr)
btc <- ddply(bc, c("from", "to"), summarize, value=sum(value))
btc
library(igraph)
btc.net <- graph.data.frame(btc, directed=T)
V(btc.net)$color <- "blue"
V(btc.net)$color[unlist(V(btc.net)$name) == seed] <- "red"
nodes <- unlist(V(btc.net)$name)
E(btc.net)$width <- log(E(btc.net)$value)/10
plot.igraph(btc.net, vertex.size=5, edge.arrow.size=0.1, vertex.label=NA, main=paste("BTC transaction network for\n", seed))
install.packages("igraph")
library(igraph)
btc.net <- graph.data.frame(btc, directed=T)
V(btc.net)$color <- "blue"
V(btc.net)$color[unlist(V(btc.net)$name) == seed] <- "red"
nodes <- unlist(V(btc.net)$name)
E(btc.net)$width <- log(E(btc.net)$value)/10
plot.igraph(btc.net, vertex.size=5, edge.arrow.size=0.1, vertex.label=NA, main=paste("BTC transaction network for\n", seed))
library(devtools)
library(httr)
library(lubridate)
library(odessa)
library(forecast)
url <- "http://api.panoptez.ml/v1/twitter/query/timeline/3.json?start=2015-06-04&stop=2015-06-04&app_id=APP_ID&app_key=APP_KEY"
response <- GET(url)
raw <- content(response)
raw
# https://pushover.net/apps/aiW2VbcFvRGxNWMezVEukqMXjXZoiG
library(pushover)
set_pushover_app(user= 'utwymWLq9BbzyeNtF7ZhznbjhY7hHj', token= 'aiW2VbcFvRGxNWMezVEukqMXjXZoiG')
install.packages("pushoverr")
# https://pushover.net/apps/aiW2VbcFvRGxNWMezVEukqMXjXZoiG
library(pushover)
set_pushover_app(user= 'utwymWLq9BbzyeNtF7ZhznbjhY7hHj', token= 'aiW2VbcFvRGxNWMezVEukqMXjXZoiG')
# https://pushover.net/apps/aiW2VbcFvRGxNWMezVEukqMXjXZoiG
library(pushoverr)
set_pushover_app(user= 'utwymWLq9BbzyeNtF7ZhznbjhY7hHj', token= 'aiW2VbcFvRGxNWMezVEukqMXjXZoiG')
url <- "http://api.panoptez.ml/v1/twitter/query/timeline/3.json?start=2015-06-04&stop=2015-06-04&app_id=2940620356&app_key=xUrz8pSfIX8w7q8I6cidGkd7r"
response <- GET(url)
raw <- content(response)
raw
url <- "http://api.panoptez.ml/v1/twitter/query/timeline/3.json?start=2015-06-04&stop=2015-06-04&app_id=f45d58da&app_key=8d2c446cb5be8beddb8f48719f7fbd13"
response <- GET(url)
raw <- content(response)
raw
library(RJDBC)
install.packages("RJDBC")
library(RJDBC)
install.packages(c("rJava", "RJDBC"))
install.packages(c("rJava", "RJDBC"))
library(RJDBC)
drv <-
JDBC("com.amazon.hive.jdbc3.HS2Driver","/home/hadoop/hivejdbc/4/HiveJDBC4.jar",identifier.q
uote="`")
conn <- dbConnect(drv, "jdbc:hive2://localhost:12000/default", "", "")
drv <- JDBC("com.amazon.hive.jdbc3.HS2Driver","/home/hadoop/hivejdbc/4/HiveJDBC4.jar",identifier.quote="`")
conn <- dbConnect(drv, "jdbc:hive2://localhost:12000/default", "", "")
drv <- JDBC("com.amazon.hive.jdbc3.HS2Driver","/home/hadoop/hivejdbc/4/HiveJDBC4.jar",identifier.quote="`")
getwd()
library(RJDBC)
drv <-
JDBC("com.amazon.hive.jdbc3.HS2Driver","/home/hadoop/hivejdbc/4/HiveJDBC4.jar",identifier.q
uote="`")
conn <- dbConnect(drv, "jdbc:hive2://localhost:12000/default", "", "")
drv <- JDBC("com.amazon.hive.jdbc3.HS2Driver","/home/hadoop/hivejdbc/4/HiveJDBC4.jar",identifier.quote="`")
devtools::install_github("timelyportfolio/flowtypeR")
# using about.html from R help
library("flowtypeR")
library("htmltools")
library("shiny")
# read about.html from the R system help directory
about_html <- readLines(file.path(R.home("doc/html"),"about.html"))
browsable(
tagList(
bootstrapPage(
tags$div(class="row"
,tags$div(class="col-xs-6"
,tags$h1("with flowtype")
,tags$div(
id="flowtype-resize"
,style="padding:0em 1em 0em 1em; border: 2px solid gray;"
,HTML(
about_html[do.call(seq,as.list(grep(x=about_html,pattern="<h2>")+c(0,-1)))]
)
)
)
,tags$div(class="col-xs-6"
,tags$h1("without flowtype")
,tags$div(id="flowtype-resize"
,style="padding:0em 1em 0em 1em; border: 2px dashed gray;"
,HTML(
about_html[do.call(seq,as.list(grep(x=about_html,pattern="<h2>")+c(0,-1)))]
)
)
)
)
)
,flowtype(
'#flowtype-resize'
,minFont = 12
,fontRatio = 20
)
)
)
about_html <- readLines(file.path(R.home("doc/html"),"about.html"))
R.home("doc/html")
file.path(R.home("doc/html"),"about.html")
about_html <- readLines(file.path(R.home("doc/html"),"about.html"))
about_html <- readLines(file.path(R.home("doc/html"),"COPYING"))
about_html <- readLines(file.path(R.home(""),"COPYING"))
about_html
browsable(
tagList(
bootstrapPage(
tags$div(class="row"
,tags$div(class="col-xs-6"
,tags$h1("with flowtype")
,tags$div(
id="flowtype-resize"
,style="padding:0em 1em 0em 1em; border: 2px solid gray;"
,HTML(
about_html[do.call(seq,as.list(grep(x=about_html,pattern="<h2>")+c(0,-1)))]
)
)
)
,tags$div(class="col-xs-6"
,tags$h1("without flowtype")
,tags$div(id="flowtype-resize"
,style="padding:0em 1em 0em 1em; border: 2px dashed gray;"
,HTML(
about_html[do.call(seq,as.list(grep(x=about_html,pattern="<h2>")+c(0,-1)))]
)
)
)
)
)
,flowtype(
'#flowtype-resize'
,minFont = 12
,fontRatio = 20
)
)
)
library(dplyr)
"http://www.norvig.com/big.txt" %>%
readLines() %>%
paste(collapse = " ") %>%
tolower %>%
strsplit("[^a-z]+") %>%
table() %>%
sort(decreasing = TRUE) %>%
names() ->
sorted_words
"http://www.norvig.com/big.txt" %>%
url() %>%
readLines() %>%
paste(collapse = " ") %>%
tolower %>%
strsplit("[^a-z]+") %>%
table() %>%
sort(decreasing = TRUE) %>%
names() ->
sorted_words
"http://www.norvig.com/big.txt" %>%
url() %>%
readLines(n = 1e1L)
"http://www.norvig.com/big.txt" %>%
url()
"http://www.norvig.com/big.txt" %>%
url() %>%
readLines(n = 1e1L)
sorted_words <- names(sort(table(strsplit(tolower(paste(readLines("http://www.norvig.com/big.txt"), collapse = " ")), "[^a-z]+")), decreasing = TRUE))
args(readLines)
"http://www.google.com" %>%
url() %>%
readLines(n = 1e1L)
"https://www.norvig.com/big.txt" %>%
url() %>%
readLines(n = 1e1L)
readLines('http://www.norvig.com/big.txt', n = 1)
readLines('http://www.norvig.com/big.txt/', n = 1)
readLines(url('http://www.norvig.com/big.txt'), n = 1)
url('http://www.norvig.com/big.txt')
urls <- "google.com"
sorted_words <- names(sort(table(strsplit(tolower(paste(readLines(urls), collapse = " ")), "[^a-z]+")), decreasing = TRUE))
urls <- "http://www.google.com"
readLines(urls)
sorted_words <- names(sort(table(strsplit(tolower(paste(readLines(urls), collapse = " ")), "[^a-z]+")), decreasing = TRUE))
correct <- function(word) { c(sorted_words[ adist(word, sorted_words) <= min(adist(word, sorted_words), 2)], word)[1] }
correct("piese")
correct("ov")
correct("cakke")
library(h20)
install.packages("h2o")
library(h2o)
h20.init()
h2o.init()
system.time(df  <- h2o.importFile("/dev/shm/test.csv"))
system.time(df  <- h2o.importFile("/data/2007.csv.gz"))
system.time(df  <- h2o.importFile("~/data/2007.csv.gz"))
getwd()
system.time(df  <- h2o.importFile("/home/ttmmghmm/data/2007.csv.gz"))
system.time(df  <- h2o.importFile("https://s3-eu-west-1.amazonaws.com/cloud-data-lab-2/test1/cable_db_full.7z"))
system.time(df  <- h2o.importFile(url("https://s3-eu-west-1.amazonaws.com/cloud-data-lab-2/test1/cable_db_full.7z")))
system.time(df  <- h2o.importURL(url("https://s3-eu-west-1.amazonaws.com/cloud-data-lab-2/test1/cable_db_full.7z")))
?h2o.importFolder
examples(h2o.importFolder)
example(h2o.importFolder)
str(prostate.hex)
head(prostate.hex)
prostate.hex = h2o.uploadFile(localH2O, path = prosPath, destination_frame = "prostate.hex")
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE)
prosPath = system.file("extdata", "prostate.csv", package = "h2o")
prostate.hex = h2o.uploadFile(localH2O, path = prosPath, destination_frame = "prostate.hex")
class(prostate.hex)
summary(prostate.hex)
prosPath
str(prostate.hex)
head(prostate.hex)
nrow(prostate.hex)
prostate.hex
gaAuth <- c(projectId = 'api-project-572780019748', projectNum = '572780019748')
library(bigrquery)
project <- gaAuth["projectId"]
sql <-'SELECT * FROM [bigquery-samples:nasdaq_stock_quotes.quotes] LIMIT 10'
query_exec(sql, project = project)
demo("oauth2-github", package = "httr", ask = FALSE)
set.seed(1) ; n<-100
x<-matrix(runif(n^2),n,n) ; cor<-cor(x)
# Set diagonal and one triangle to to 0:
diag(cor) <- 0 ; cor[upper.tri(cor)] <- 0
sort <- sort(cor) # Get sorted values:
# Create a dummy matrix and get lowest 5:
min <- matrix(cor %in% sort[1:5] ,n,n) ; which(min,arr.ind=T)
# Same for highest 5:
max <- matrix(cor %in% sort[(n^2-5):(n^2)] ,n,n) ; which(max,arr.ind=T)
# qgraph, which can be used to visualize a correlation matrix as a network:
library(qgraph)
qgraph(cor(x),vsize=2,minimum=0.2,filetype="png")
install.packages("qgraph")
library(qgraph)
Error in library(qgraph) : there is no package called ‘qgraph’
> qgraph(cor(x),vsize
library(ggplot2)
library(dplyr)
#Effective date for same-sex marraige from
#https://en.wikipedia.org/wiki/Same-sex_marriage_in_the_United_States
#with June 2015 for states that had not approved by that date
#Republican two-party vote share in the 2012 election from
#usaelectionatlas.org h/t David Rothschild
df=structure(list(state = structure(1:50, .Label = c("Alabama",
"Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut",
"Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois",
"Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine",
"Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi",
"Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire",
"New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota",
"Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island",
"South Carolina", "South Dakota", "Tennessee", "Texas", "Utah",
"Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin",
"Wyoming"), class = "factor"), state_abbrev = structure(c(2L,
1L, 4L, 3L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 13L, 14L, 15L, 12L,
16L, 17L, 18L, 21L, 20L, 19L, 22L, 23L, 25L, 24L, 26L, 29L, 33L,
30L, 31L, 32L, 34L, 27L, 28L, 35L, 36L, 37L, 38L, 39L, 40L, 41L,
42L, 43L, 44L, 46L, 45L, 47L, 49L, 48L, 50L), .Label = c("AK",
"AL", "AR", "AZ", "CA", "CO", "CT", "DE", "FL", "GA", "HI", "IA",
"ID", "IL", "IN", "KS", "KY", "LA", "MA", "MD", "ME", "MI", "MN",
"MO", "MS", "MT", "NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY",
"OH", "OK", "OR", "PE", "RI", "SC", "SD", "TN", "TX", "UT", "VA",
"VT", "WA", "WI", "WV", "WY"), class = "factor"), republican_vote = c(61.21622853,
57.31529048, 54.61338022, 62.15440535, 38.12718884, 47.25199285,
41.22699363, 40.55304508, 49.55774786, 53.9566491, 28.2961515,
66.42138684, 41.42247661, 55.21113076, 47.04064807, 61.06033635,
61.54277239, 58.74682561, 42.14007861, 36.67827421, 38.21143256,
45.19946793, 46.05877354, 55.8018992, 54.77866675, 57.03423186,
61.12939027, 46.59245784, 47.16624802, 41.01530527, 44.70479535,
35.69900864, 51.0340349, 60.11789514, 48.48544746, 66.77231974,
43.72883282, 47.268066, 35.98325402, 55.3082547, 59.21849914,
60.35107153, 58.00789722, 74.6261889, 31.75274117, 48.03262331,
42.37170173, 63.67429763, 46.4836176, 71.16063401), month_effective = c(6L,
10L, 10L, 6L, 6L, 10L, 11L, 7L, 1L, 6L, 12L, 10L, 6L, 6L, 4L,
6L, 6L, 6L, 12L, 1L, 5L, 6L, 8L, 6L, 6L, 11L, 6L, 6L, 1L, 10L,
12L, 7L, 10L, 6L, 6L, 10L, 5L, 4L, 8L, 11L, 6L, 6L, 6L, 10L,
9L, 10L, 12L, 10L, 10L, 10L), year_effective = c(2015L, 2014L,
2014L, 2015L, 2008L, 2014L, 2008L, 2013L, 2015L, 2015L, 2013L,
2014L, 2014L, 2014L, 2009L, 2015L, 2015L, 2015L, 2012L, 2013L,
2004L, 2015L, 2013L, 2015L, 2015L, 2014L, 2015L, 2015L, 2010L,
2013L, 2013L, 2011L, 2014L, 2015L, 2015L, 2014L, 2014L, 2014L,
2013L, 2014L, 2015L, 2015L, 2015L, 2014L, 2009L, 2014L, 2012L,
2014L, 2014L, 2014L), effective_date = c(2015.45833333333, 2014.79166666667,
2014.79166666667, 2015.45833333333, 2008.45833333333, 2014.79166666667,
2008.875, 2013.54166666667, 2015.04166666667, 2015.45833333333,
2013.95833333333, 2014.79166666667, 2014.45833333333, 2014.45833333333,
2009.29166666667, 2015.45833333333, 2015.45833333333, 2015.45833333333,
2012.95833333333, 2013.04166666667, 2004.375, 2015.45833333333,
2013.625, 2015.45833333333, 2015.45833333333, 2014.875, 2015.45833333333,
2015.45833333333, 2010.04166666667, 2013.79166666667, 2013.95833333333,
2011.54166666667, 2014.79166666667, 2015.45833333333, 2015.45833333333,
2014.79166666667, 2014.375, 2014.29166666667, 2013.625, 2014.875,
2015.45833333333, 2015.45833333333, 2015.45833333333, 2014.79166666667,
2009.70833333333, 2014.79166666667, 2012.95833333333, 2014.79166666667,
2014.79166666667, 2014.79166666667)), .Names = c("state", "state_abbrev",
"republican_vote", "month_effective", "year_effective", "effective_date"
), row.names = c(NA, -50L), class = "data.frame")
df$effective_date = with(df,year_effective+(month_effective-.5)/12)
p=ggplot(df,aes(x=effective_date,y=republican_vote))
p=p+coord_cartesian(xlim=c(2004,2016))
p=p+scale_x_continuous(breaks=seq(2004,2016,by=2))
p=p+geom_text(aes(label=state_abbrev),jitter=TRUE)
p=p+labs(x="Date",y="Republican Vote Share\n(2012 Presidential Two-Party Share)",title="Date Same-Sex Marriage Law Effective\n(or June 26, 2015)")
p=p + geom_hline(yintercept=50)
p=p+geom_smooth(method="loess",span=1.05,se=FALSE)
p
library(sigma)
data <- system.file("examples/ediaspora.gexf.xml", package = "sigma")
sigma(data)
install.packages("sigma")
devtools::install_github('jjallaire/sigma')
library(sigma)
sigma(system.file("examples/ediaspora.gexf.xml", package = "sigma"))
library(shiny)
library(sigma)
gexf <- system.file("examples/ediaspora.gexf.xml", package = "sigma")
ui = shinyUI(fluidPage(
checkboxInput("drawEdges", "Draw Edges", value = TRUE),
checkboxInput("drawNodes", "Draw Nodes", value = TRUE),
sigmaOutput('sigma')
))
server = function(input, output) {
output$sigma <- renderSigma(
sigma(gexf,
drawEdges = input$drawEdges,
drawNodes = input$drawNodes)
)
}
shinyApp(ui = ui, server = server)
# CODE TO DOWNLOAD LOG RILES FROM RSTUDIO CRAN MIRROR
# FIND MOST DOWNLOADED PACKAGE AND PLOT DOWNLOADS
# FOR SELECTED PACKAGES
# -----------------------------------------------------------------
library(installr)
library(ggplot2)
library(data.table) #for downloading
# ----------------------------------------------------------------
# Read data from RStudio site
RStudio_CRAN_dir <- download_RStudio_CRAN_data(START = '2015-05-15',END = '2015-06-15',
log_folder="C:/DATA/test3")
# read .gz compressed files form local directory
RStudio_CRAN_data <- read_RStudio_CRAN_data(RStudio_CRAN_dir)
#> RStudio_CRAN_data <- read_RStudio_CRAN_data(RStudio_CRAN_dir)
#Reading C:/DATA/test3/2015-05-15.csv.gz ...
#Reading C:/DATA/test3/2015-05-16.csv.gz ...
#Reading C:/DATA/test3/2015-05-17.csv.gz ...
#Reading C:/DATA/test3/2015-05-18.csv.gz ...
#Reading C:/DATA/test3/2015-05-19.csv.gz ...
#Reading C:/DATA/test3/2015-05-20.csv.gz ...
#Reading C:/DATA/test3/2015-05-21.csv.gz ...
#Reading C:/DATA/test3/2015-05-22.csv.gz ...
dim(RStudio_CRAN_data)
# [1] 8055660      10
# Find the most downloaded packages
pkg_list <- most_downloaded_packages(RStudio_CRAN_data)
pkg_list
#Rcpp  stringr  ggplot2  stringi magrittr     plyr
#125529   115282   103921   103727   102083    97183
lineplot_package_downloads(names(pkg_list),RStudio_CRAN_data)
# Look at plots for some packages
barplot_package_users_per_day("checkpoint",RStudio_CRAN_data)
#$total_installations
#[1] 359
barplot_package_users_per_day("Rcpp", RStudio_CRAN_data)
#$total_installations
install.packages("installr")
# CODE TO DOWNLOAD LOG RILES FROM RSTUDIO CRAN MIRROR
# FIND MOST DOWNLOADED PACKAGE AND PLOT DOWNLOADS
# FOR SELECTED PACKAGES
# -----------------------------------------------------------------
library(installr)
library(ggplot2)
library(data.table) #for downloading
# ----------------------------------------------------------------
# Read data from RStudio site
RStudio_CRAN_dir <- download_RStudio_CRAN_data(START = '2015-05-15',END = '2015-06-15',
log_folder="C:/DATA/test3")
# read .gz compressed files form local directory
RStudio_CRAN_data <- read_RStudio_CRAN_data(RStudio_CRAN_dir)
#> RStudio_CRAN_data <- read_RStudio_CRAN_data(RStudio_CRAN_dir)
#Reading C:/DATA/test3/2015-05-15.csv.gz ...
#Reading C:/DATA/test3/2015-05-16.csv.gz ...
#Reading C:/DATA/test3/2015-05-17.csv.gz ...
#Reading C:/DATA/test3/2015-05-18.csv.gz ...
#Reading C:/DATA/test3/2015-05-19.csv.gz ...
#Reading C:/DATA/test3/2015-05-20.csv.gz ...
#Reading C:/DATA/test3/2015-05-21.csv.gz ...
#Reading C:/DATA/test3/2015-05-22.csv.gz ...
dim(RStudio_CRAN_data)
# [1] 8055660      10
# Find the most downloaded packages
pkg_list <- most_downloaded_packages(RStudio_CRAN_data)
pkg_list
#Rcpp  stringr  ggplot2  stringi magrittr     plyr
#125529   115282   103921   103727   102083    97183
lineplot_package_downloads(names(pkg_list),RStudio_CRAN_data)
# Look at plots for some packages
barplot_package_users_per_day("checkpoint",RStudio_CRAN_data)
#$total_installations
#[1] 359
barplot_package_users_per_day("Rcpp", RStudio_CRAN_data)
#$total_installations
install.packages("installr")
