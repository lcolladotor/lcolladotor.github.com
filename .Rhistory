# Note that the sorting direction depends on type.
# For each price level find the total volume which will be sold/bought.
aggregate_bids <-
group_by(Type, Price) %,%
summarize(Quantity = sum(Quantity)) %,%
ungroup %,%
arrange(Price*(1 - 2*(Type == "Buy"))) %,%
mutate(Quantity = Quantity %>% cumsum)
# Group the data, aggregate the bids, and plot the supply and demand curves.
auction.data %>%
group_by(Type) %>%
do(aggregate_bids(.)) %>%
qplot(Quantity, Price, col = Type, geom = "step", data = .) %>%
print
library(ggplot2)
# Define a function that aggregates the bid data for a type.
# Note that the sorting direction depends on type.
# For each price level find the total volume which will be sold/bought.
aggregate_bids <-
group_by(Type, Price) %,%
summarize(Quantity = sum(Quantity)) %,%
ungroup %,%
arrange(Price*(1 - 2*(Type == "Buy"))) %,%
mutate(Quantity = Quantity %>% cumsum)
# Group the data, aggregate the bids, and plot the supply and demand curves.
auction.data %>%
group_by(Type) %>%
do(aggregate_bids(.)) %>%
qplot(Quantity, Price, col = Type, geom = "step", data = .) %>%
print
library(dplyr)
# Define a function that aggregates the bid data for a type.
# Note that the sorting direction depends on type.
# For each price level find the total volume which will be sold/bought.
aggregate_bids <-
group_by(Type, Price) %,%
summarize(Quantity = sum(Quantity)) %,%
ungroup %,%
arrange(Price*(1 - 2*(Type == "Buy"))) %,%
mutate(Quantity = Quantity %>% cumsum)
# Group the data, aggregate the bids, and plot the supply and demand curves.
auction.data %>%
group_by(Type) %>%
do(aggregate_bids(.)) %>%
qplot(Quantity, Price, col = Type, geom = "step", data = .) %>%
print
# Define a function that aggregates the bid data for a type.
# Note that the sorting direction depends on type.
# For each price level find the total volume which will be sold/bought.
aggregate_bids <-
group_by(Type, Price) %,%
summarize(Quantity = sum(Quantity)) %,%
ungroup %,%
arrange(Price*(1 - 2*(Type == "Buy"))) %,%
mutate(Quantity = Quantity %>% cumsum)
# Group the data, aggregate the bids, and plot the supply and demand curves.
auction.data %>%
group_by(Type) %>%
do(aggregate_bids(.)) %>%
qplot(Quantity, Price, col = Type, geom = "step", data = .) %>%
print
library(magrittr)
library(SparkR)
sc <- sparkR.init(master="local")
sc %>%
parallelize(1:100000) %>%
count
nums = runif(100000) * 10
sc %>%
parallelize(nums) %>%
map(function(x) round(x)) %>%
filterRDD(function(x) x %% 2) %>%
map(function(x) list(x, 1)) %>%
reduceByKey(function(x,y) x + y, 1L) %>%
collect
nums = runif(100000) * 10
sc %>%
parallelize(nums) %>%
map(function(x) round(x)) %>%
filterRDD(function(x) x %% 2) %>%
map(function(x) list(x, 1)) %>%
reduceByKey(function(x,y) x + y, 1L) %>%
collect
good.times <-
Sys.Date() %>%
as.POSIXct %>%
seq(by = "15 mins", length.out = 100) %>%
data.frame(timestamp = .)
good.times
good.times <-
Sys.Date() %>%
as.POSIXct %>%
seq(by = "15 mins", length.out = 100) %>%
data.frame(timestamp = .)  %T>% (. %>% head %>% print) %>% tail(4)
good.times
good.times <-
Sys.Date() %>%
as.POSIXct %>%
#seq(by = "15 mins", length.out = 100) %>%
data.frame(timestamp = .)  %T>% (. %>% head %>% print) %>% tail(4)
good.times
good.times <-
Sys.Date() %>%
as.POSIXct %>%
#seq(by = "15 mins", length.out = 100) %>%
data.frame(timestamp = .)  %T>% (. %>% head %>% print) %>% tail(4)
good.times <-
Sys.Date() %>%
as.POSIXct %>%
#seq(by = "15 mins", length.out = 100) %>%
data.frame(timestamp = .)  %T>% (. %>% head %>% print) %>% tail(4)
good.times <-
Sys.Date() %>%
as.POSIXct %>%
#seq(by = "15 mins", length.out = 100) %>%
data.frame(timestamp = .)  %T>% (. %>% head %>% print) %>% tail(4)
good.times <-
Sys.Date() %>%
#as.POSIXct %>%
#seq(by = "15 mins", length.out = 100) %>%
data.frame(timestamp = .)  %T>% (. %>% head %>% print) %>% tail(4)
good.times <-
Sys.Date() %>%
#as.POSIXct %>%
seq(by = "15 mins", length.out = 100) %>%
data.frame(timestamp = .)  %T>% (. %>% head %>% print) %>% tail(4)
good.times <-
Sys.Date() %>%
as.POSIXct %>%
seq(by = "15 mins", length.out = 100) %>%
data.frame(timestamp = .)  %T>% (. %>% head %>% print) %>% tail(4)
good.times$quarter <-
good.times %>%
use_series(timestamp) %>%
format("%M") %>%
as.numeric %>%
divide_by_int(15) %>%
add(1)
good.times$quarter
good.times
#good.times$quarter <-
good.times %>%
#   use_series(timestamp) %>%
#  format("%M") %>%
# as.numeric %>%
#divide_by_int(15) %>%
#add(1)
1
#good.times$quarter <-
good.times #%>%
#   use_series(timestamp) %>%
#  format("%M") %>%
# as.numeric %>%
#divide_by_int(15) %>%
#add(1)
good.times %>%
use_series(timestamp)
?use_series
good.times
good.times %>%
use_series(timestamp) %>%
format("%M")
good.times %>%
use_series(timestamp) %>%
format("%M") %>%
as.numeric
good.times %>%
use_series(timestamp) %>%
format("%M") %>%
as.numeric %>%
divide_by_int(15) %>%
add(1)
iris %>%
lm(Sepal.Length ~ ., .)
fit <-
iris %>%
lm(Sepal.Length ~ ., .)
new.fit <-
fit %>%
update(. ~ . - Species)
fit
fit %>%
update(. ~ . - Species)
# Examples using anonymous functions:
iris %>%
function(x) {
rbind(x %>% head, x %>% tail)
}
iris %>%
lambda({ rbind(x %>% head, x %>% tail) })
iris %>%
l({ rbind(x %>% head, x %>% tail)})
# Examples using anonymous functions:
iris %>%
( function(x) {
rbind(x %>% head, x %>% tail)
})
iris %>%
lambda({ rbind(x %>% head, x %>% tail) })
iris %>%
l({ rbind(x %>% head, x %>% tail)})
# Examples using anonymous functions:
iris %>%
( function(x) {
rbind(x %>% head, x %>% tail)
})
# Examples using anonymous functions:
iris %>%
( .  %>%
rbind(. %>% head, . %>% tail)
)
# Examples using anonymous functions:
iris %>%
( .  %>%
{ rbind(. %>% head, . %>% tail) }
)
# Examples using anonymous functions:
iris %>%
{ rbind(. %>% head, . %>% tail) }
1:10 %T>% plot(type = "l") %>% multiply_by(2)
# Define a logging function
logger <- function(x)
cat(as.character(Sys.time()), ":", nrow(x), "\n")
# Create a pipe using the logger.
`%L>%` <- pipe_with(logger)
# Define a logging function
logger <- .   %>% cat(as.character(Sys.time()), ":", nrow(.), "\n")
iris %$%
Species %>%
levels
iris %>%
plot(Sepal.Length ~ Sepal.Width, data = .)
iris %$%
ts.plot(Sepal.Length)
[
iris %$%
ts.plot(Sepal.Length)
mtcars %>%
subset(hp > 100) %>%
aggregate(. ~ cyl, data = ., FUN = . %>% mean %>% round(2)) %>%
transform(kpl = mpg %>% multiply_by(0.4251)) %>%
print
x <- mtcars %>%
subset(hp > 100) %>%
aggregate(. ~ cyl, data = ., FUN = . %>% mean %>% round(2)) %>%
transform(kpl = mpg %>% multiply_by(0.4251)) %>%
print
x
x <- mtcars %>%
subset(hp > 100) %>%
aggregate(. ~ cyl, data = ., FUN = . %>% mean %>% round(2)) %>%
transform(kpl = mpg %>% multiply_by(0.4251)) # %>% print
x
x <- mtcars %>% print  %>%
subset(hp > 100) %>%
aggregate(. ~ cyl, data = ., FUN = . %>% mean %>% round(2)) %>%
transform(kpl = mpg %>% multiply_by(0.4251)) # %>% print
x
x <- mtcars %>%
subset(hp > 100) %>% print  %>%
aggregate(. ~ cyl, data = ., FUN = . %>% mean %>% round(2)) %>%
transform(kpl = mpg %>% multiply_by(0.4251)) # %>% print
x <- mtcars %>%
subset(hp > 100) %>% # print  %>%
aggregate(. ~ cyl, data = ., FUN = . %>% mean %>% round(2)) %>%
transform(kpl = mpg %>% multiply_by(0.4251)) # %>% print
x
car_data %>%
{
if (nrow(.) > 0)
rbind(head(., 1), tail(., 1))
else .
}
car_data %>%
(function(x) {
if (nrow(x) > 2)
rbind(head(x, 1), tail(x, 1))
else x
})
1:10 %>% (substitute(f(), list(f = sum)))
iris$Sepal.Length %<>% sqrt
iris
iris$Sepal.Length %<>% sqrt
rnorm(1000)    %>%
multiply_by(5) %>%
add(5)         %>%
{
cat("Mean:", mean(.),
"Variance:", var(.), "\n")
head(.)
}
library(magrittr)
library(SparkR)
sc <- sparkR.init(master="local")
sc %>%
parallelize(1:100000) %>%
count
set.seed(1) # reproducability
# Utility function for sampling.
sample_with_replace <-
function(v, n = 100) sample(v, size = n, replace = TRUE)
# Generate some auction data for the example.
auction.data <-
data.frame(
Price    = 1:100 %>% sample_with_replace,
Quantity = 1:10  %>% sample_with_replace,
Type     =
0:1 %>%
sample_with_replace %>%
factor(labels = c("Buy", "Sell"))
) %T>%
( . %>% head %>% print )
sc <- sparkR.init(master="local")
sample_cw <- function(n, s){
set.seed(s)
ChickWeight[sample(nrow(ChickWeight), n), ]
}
data_rdd <- sc %>%
parallelize(1:200, 20) %>%
map(function(s) sample_cw(250, s))
nums = runif(100000) * 10
sc %>%
parallelize(nums) %>%
map(function(x) round(x)) %>%
filterRDD(function(x) x %% 2) %>%
map(function(x) list(x, 1)) %>%
reduceByKey(function(x,y) x + y, 1L) %>%
collect
sc <- sparkR.init(master="local")
sample_cw <- function(n, s){
set.seed(s)
ChickWeight[sample(nrow(ChickWeight), n), ]
}
data_rdd <- sc %>%
parallelize(1:200, 20) %>%
map(function(s) sample_cw(250, s))
data_rdd %>%
map(function(x) mean(x$weight)) %>%
collect %>%
as.numeric %>%
hist(20, main="mean weight, bootstrap samples")
Or you can use it to perform bootstrapped regressions.
train_lm <- function(data_in){
lm(data=data_in, weight ~ Time)
}
coef_rdd <- data_rdd %>%
map(train_lm) %>%
map(function(x) x$coefficients)
get_coef <- function(k){
coef_rdd %>%
map(function(x) x[k]) %>%
collect %>%
as.numeric
}
df <- data.frame(intercept = get_coef(1), time_coef = get_coef(2))
df$intercept %>% hist(breaks = 30, main="beta coef for intercept")
df$time_coef %>% hist(breaks = 30, main="beta coef for time")
data_rdd %>%
map(function(x) mean(x$weight)) %>%
collect %>%
as.numeric %>%
hist(20, main="mean weight, bootstrap samples")
Or you can use it to perform bootstrapped regressions.
train_lm <- function(data_in){
lm(data=data_in, weight ~ Time)
}
coef_rdd <- data_rdd %>%
map(train_lm) %>%
map(function(x) x$coefficients)
get_coef <- function(k){
coef_rdd %>%
map(function(x) x[k]) %>%
collect %>%
as.numeric
}
df <- data.frame(intercept = get_coef(1), time_coef = get_coef(2))
df$intercept %>% hist(breaks = 30, main="beta coef for intercept")
df$time_coef %>% hist(breaks = 30, main="beta coef for time")
devtools::use_testthat()
devtools::use_testthat()
library(wakefield)
library(tidyr)
library(dplyr)
library(data.table)
x <- r_data_frame(n=10,id,date_stamp(name='foo',random=TRUE))
y <- r_data_frame(n=10,id,date_stamp(name='bar',random=TRUE))
x$foo[base::sample(10,5)] <- NA
y$bar[base::sample(10,5)] <- NA
install.packages("tidyr")
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("trinker/wakefield")
pacman::p_load(dplyr, tidyr, ggplot2)
devtools::dev_mode(TRUE)
devtools::install_github("lionel-/magrittr", ref = "monads")
%,%
x  <- . %,% 1:10
library(magrittr)
x  <- . %,% 1:10
Q
q()
exit
Q
devtools::dev_mode(FALSE)
?devtools::dev_mode
library(magrittr)
1 %,% sdf
library(wakefield)
library(tidyr)
library(dplyr)
library(data.table)
x <- r_data_frame(n=10,id,date_stamp(name='foo',random=TRUE))
y <- r_data_frame(n=10,id,date_stamp(name='bar',random=TRUE))
x$foo[base::sample(10,5)] <- NA
y$bar[base::sample(10,5)] <- NA
full_join(x,y,by='ID') %>% mutate(start = pmin(foo, bar, na.rm = TRUE))
full_join(x,y,by='ID') %>% data.table %>% .[, start := pmin(foo, bar, na.rm = T)] %>% print
full_join(x,y,by='ID') %>% data.table %>% .[, start := pmin(foo, bar, na.rm = T)] %>% print
full_join(x,y,by='ID') %>% data.table
full_join(x,y,by='ID')
library(magrittr)
library(SparkR)
sc <- sparkR.init(master="local")
sc %>%
parallelize(1:100000) %>%
count
library(MonetDB.R)
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/demo")
library(MonetDB.R)
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/demo")
?dbConnect
library(MonetDB.R)
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/demo", port = 32768)
?dbDriver
library(MonetDB.R)
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost", port = 32768)
library(MonetDB.R)
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/", port = 32768)
library(MonetDB.R)
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/", port = 32768)
library(MonetDB.R)
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/", port = 32770)
library(MonetDB.R)
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/voc", port = 32770)
conn2 <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/voc")
conn2 <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost")
conn
# write some test data
data(iris)
dbWriteTable(conn, "iris", iris)
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/demo")
conn <- dbConnect(dbDriver("MonetDB"), "monetdb://localhost/voc")
# write some test data
data(iris)
dbWriteTable(conn, "iris", iris)
ds1 <- dbGetQuery(conn,"SELECT avg(sepal_width) FROM iris")
ds1
?MonetDB.R
conn2 <- dbConnect(MonetDB.R(), "monetdb://localhost/demo")
conn2 <- dbConnect(MonetDB.R(), "monetdb://localhost/demo")
# start with an example data set
nrow( mtcars )
# and a MonetDB.R connection
db <- conn
# here's how many records you'd have if you stack your example data three times
data(mtcars) ; nrow( mtcars ) * 3
# write to three separate tables
dbWriteTable( db , 'mtcars1' , mtcars )
dbWriteTable( db , 'mtcars2' , mtcars )
dbWriteTable( db , 'mtcars3' , mtcars )
# stack them all
dbSendUpdate( db , "CREATE TABLE mtcars AS SELECT * FROM mtcars1 UNION ALL SELECT * FROM mtcars2 UNION ALL SELECT * FROM mtcars3 WITH DATA" )
# correct number of records
nrow( dbReadTable( db , 'mtcars' ) )
# write test data to temporary CSV file
data(iris)
file <- tempfile()
write.table(iris, file, sep=",")
# create table and import CSV
monetdb.read.csv(conn, file, "iris", 150)
# write test data to temporary CSV file
data(iris)
file <- tempfile()
write.table(iris2, file, sep=",")
# create table and import CSV
monetdb.read.csv(conn, file, "iris2", 150)
tempfiles()
tempfile()
iris2
# write test data to temporary CSV file
data(iris)
file <- tempfile()
write.table(iris, file, sep=",")
# create table and import CSV
monetdb.read.csv(conn, file, "iris2", 150)
file
> monetdb.read.csv(conn, file, "iris2", 150)
monetdb.read.csv(conn, file, "iris2", 150)
monetdb.read.csv(conn, file, "iris2", 150, over = T)
?monetdb.read.csv
monetdb.read.csv(conn, file, "iris2", 150, overwrite = T)
monetdb.read.csv(conn, file, "iris2", 150, overwrite = TRUE)
monetdb.read.csv(conn, file, "iris2", 150, append = TRUE)
monetdb.read.csv(conn, file, "iris2", append = TRUE)
monetdb.read.csv(conn, file, "iris2")
monetdb.read.csv(conn, file, "iris3")
file <- tempfile()
write.table(iris, file, sep=",")
# create table and import CSV
# write test data to temporary CSV file
ls ()
rm (iris)
rm (iris2)
